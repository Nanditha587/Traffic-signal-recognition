{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMKKC0YvXuA0CCZdRzooKe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nanditha587/Traffic-signal-recognition/blob/main/Another_copy_of_CNN_Traffic_Signs_Final_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "print(\"Drive mounted.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkRPlhg7cXbe",
        "outputId": "bebc13f0-bf19-42ff-e1aa-0d41349fa9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Drive mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ZIP_FILE_PATH = '/content/gdrive/MyDrive/traffic signals.zip'\n",
        "UNZIP_DESTINATION = '/content/GTSRB_Data/'\n",
        "!mkdir -p \"$UNZIP_DESTINATION\"\n",
        "!unzip -q \"$ZIP_FILE_PATH\" -d \"$UNZIP_DESTINATION\"\n",
        "\n",
        "print(\"\\n--- Unzipping Started ---\")\n",
        "print(f\"Images will be extracted to: {UNZIP_DESTINATION}. Please wait for the cell to finish executing.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hv2ydpodB8V",
        "outputId": "0d7df537-cc6e-4eb3-879d-c128621c2d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Unzipping Started ---\n",
            "Images will be extracted to: /content/GTSRB_Data/. Please wait for the cell to finish executing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from glob import glob\n",
        "import os"
      ],
      "metadata": {
        "id": "PHXcJA6Cdk3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dir = '/content/GTSRB_Data/Train/'\n",
        "NUM_CLASSES = 43\n",
        "IMG_SIZE = 30\n",
        "try:\n",
        "    class_folders = os.listdir(train_dir)\n",
        "    print(f\"Found {len(class_folders)} subdirectories (classes) in the training folder.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Could not find the directory at {train_dir}. Check your unzipping location.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFc3RBjjd0G6",
        "outputId": "9528e5d8-4d37-49eb-e82f-f69e04091db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 43 subdirectories (classes) in the training folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nEebnM87l3SD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!ls -F /content/GTSRB_Data/Train/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ade8BCH1jaYc",
        "outputId": "65a6ad15-dc6c-450c-ad63-0ff4287fc0b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0/   11/  14/  17/  2/\t 22/  25/  28/\t30/  33/  36/  39/  41/  6/  9/\n",
            "1/   12/  15/  18/  20/  23/  26/  29/\t31/  34/  37/  4/   42/  7/\n",
            "10/  13/  16/  19/  21/  24/  27/  3/\t32/  35/  38/  40/  5/\t 8/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dir = '/content/GTSRB_Data/Train/'\n",
        "X_data = []\n",
        "y_labels = []\n",
        "\n",
        "NUM_CLASSES = 43\n",
        "IMG_SIZE = 30\n",
        "\n",
        "print(\"Starting image loading.\")\n",
        "\n",
        "\n",
        "for i in range(NUM_CLASSES):\n",
        "    folder_name = str(i)\n",
        "    path = os.path.join(train_dir, folder_name)\n",
        "\n",
        "    if not os.path.isdir(path):\n",
        "\n",
        "        continue\n",
        "\n",
        "    images = os.listdir(path)\n",
        "\n",
        "\n",
        "    for img in images:\n",
        "        if not img.endswith(('.png', '.ppm', '.jpg')):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            image_path = os.path.join(path, img)\n",
        "            image = cv2.imread(image_path)\n",
        "\n",
        "            if image is None:\n",
        "                continue\n",
        "\n",
        "            image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "            X_data.append(np.array(image))\n",
        "            y_labels.append(i)\n",
        "\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "print(\"Image loading complete.\")\n",
        "print(f\"Total images loaded: {len(X_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k05IGbyKji6Q",
        "outputId": "8104e81a-40f9-4f94-f4be-572ae9506e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting image loading.\n",
            "Image loading complete.\n",
            "Total images loaded: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X = np.array(X_data)\n",
        "y = np.array(y_labels)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = X_train / 255.0\n",
        "X_val = X_val / 255.0\n",
        "\n",
        "\n",
        "y_train_encoded = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
        "y_val_encoded = to_categorical(y_val, num_classes=NUM_CLASSES)\n",
        "\n",
        "print(\"Final Preprocessing Complete.\")\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Validation set shape: {X_val.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "ID3vnk8XjzTS",
        "outputId": "44f8dabe-0fda-41ca-8fde-61a497c637c0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-439952972.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 2. Split data into training and validation sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# We hold out 20% for validation/testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 3. Normalize image data (Crucial for Neural Networks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2851\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2852\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2482\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = Sequential([\n",
        "\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5), Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"\\nBaseline CNN Model Architecture Defined and Compiled.\")\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "oGYo_XOWkDuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit(X_train, y_train_encoded,\n",
        "                    epochs=15,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val, y_val_encoded),\n",
        "                    verbose=1)\n",
        "\n",
        "print(\"\\nModel training started. Wait for 15 epochs to complete.\")"
      ],
      "metadata": {
        "id": "5s5IK6G9kY5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss, accuracy = model.evaluate(X_val, y_val_encoded, verbose=0)\n",
        "print(f\"\\nFinal Validation Accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"Final Validation Loss: {loss:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RgOa4WaArfQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TEST_IMAGE_PATH = '/content/test_u_turn.png'\n",
        "IMG_SIZE = 30\n",
        "TRUE_LABEL = 33\n",
        "try:\n",
        "    image = cv2.imread(TEST_IMAGE_PATH)\n",
        "\n",
        "    if image is None:\n",
        "        print(f\"Error: Image not found at {TEST_IMAGE_PATH}. Please check the filename.\")\n",
        "    else:\n",
        "\n",
        "        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "\n",
        "        normalized_image = image / 255.0\n",
        "\n",
        "\n",
        "        input_data = np.expand_dims(normalized_image, axis=0)\n",
        "\n",
        "        prediction_probs = model.predict(input_data)\n",
        "        predicted_class = np.argmax(prediction_probs)\n",
        "        confidence = np.max(prediction_probs) * 100\n",
        "\n",
        "        plt.figure(figsize=(4, 4))\n",
        "\n",
        "\n",
        "        display_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        plt.imshow(display_image)\n",
        "        plt.title(f\"Predicted Class: {predicted_class} (Conf: {confidence:.2f}%)\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"\\n--- INFERENCE RESULT ---\")\n",
        "        print(f\"True Class (U-Turn): {TRUE_LABEL}\")\n",
        "        print(f\"Model Predicted Class: {predicted_class}\")\n",
        "        print(f\"Confidence: {confidence:.2f}%\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during inference: {e}\")"
      ],
      "metadata": {
        "id": "vXpu2Ww_uZ7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!mkdir -p '/content/gdrive/MyDrive/Traffic_Sign_Model/'\n",
        "\n",
        "\n",
        "model.save('/content/gdrive/MyDrive/Traffic_Sign_Model/baseline_cnn_gtsrb.h5')\n",
        "\n",
        "print(\"Model successfully saved to your Google Drive.\")"
      ],
      "metadata": {
        "id": "NTLI3Ez2vVMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from glob import glob\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier # For k-NN"
      ],
      "metadata": {
        "id": "TCjCka9XnmHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Re-unzipping data now to ensure files exist at the local path.\")\n",
        "\n",
        "ZIP_FILE_PATH = '/content/gdrive/MyDrive/traffic signals.zip'\n",
        "\n",
        "\n",
        "UNZIP_DESTINATION = '/content/GTSRB_Data/'\n",
        "\n",
        "!mkdir -p \"$UNZIP_DESTINATION\"\n",
        "!unzip -q \"$ZIP_FILE_PATH\" -d \"$UNZIP_DESTINATION\"\n",
        "\n",
        "print(\"\\n--- Re-unzip complete. ---\")"
      ],
      "metadata": {
        "id": "7wUBTenIpPrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dir = '/content/GTSRB_Data/Train/'\n",
        "NUM_CLASSES = 43\n",
        "IMG_SIZE = 30\n",
        "X_data = []\n",
        "y_labels = []\n",
        "\n",
        "print(\"Starting image loading...\")\n",
        "\n",
        "for i in range(NUM_CLASSES):\n",
        "    folder_name = str(i)\n",
        "    path = os.path.join(train_dir, folder_name)\n",
        "\n",
        "    if not os.path.isdir(path):\n",
        "        continue\n",
        "\n",
        "    images = os.listdir(path)\n",
        "\n",
        "    for img in images:\n",
        "        if not img.endswith(('.png', '.ppm', '.jpg')):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            image_path = os.path.join(path, img)\n",
        "            image = cv2.imread(image_path)\n",
        "\n",
        "            if image is None:\n",
        "                continue\n",
        "\n",
        "            image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "            X_data.append(np.array(image))\n",
        "            y_labels.append(i)\n",
        "\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "print(f\"Total images loaded: {len(X_data)}\")\n",
        "\n",
        "\n",
        "X = np.array(X_data)\n",
        "y = np.array(y_labels)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "X_train = X_train / 255.0\n",
        "X_val = X_val / 255.0\n",
        "print(\"Data ready for feature extraction.\")"
      ],
      "metadata": {
        "id": "8JW9-wagpa8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "\n",
        "\n",
        "NUM_CLASSES = 43\n",
        "IMG_SIZE = 30\n",
        "MODEL_PATH = '/content/gdrive/MyDrive/Traffic_Sign_Model/baseline_cnn_gtsrb.h5'\n",
        "\n",
        "\n",
        "try:\n",
        "\n",
        "    model = load_model(MODEL_PATH)\n",
        "\n",
        "\n",
        "    dummy_input = tf.zeros((1, IMG_SIZE, IMG_SIZE, 3))\n",
        "    _ = model(dummy_input)\n",
        "    print(\"Model loaded and built by dummy input pass.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"FATAL: Error loading model: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "feature_layer = model.layers[-2].output\n",
        "\n",
        "\n",
        "feature_function = Model(inputs=model.layers[0].input, outputs=feature_layer)\n",
        "\n",
        "\n",
        "\n",
        "X_train_features = feature_function.predict(X_train, verbose=0)\n",
        "X_val_features = feature_function.predict(X_val, verbose=0)\n",
        "\n",
        "print(f\"Extracted feature shape (Validation Features): {X_val_features.shape}\")"
      ],
      "metadata": {
        "id": "X_PnPucZsJRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_classifier.fit(X_train_features, y_train)\n",
        "\n",
        "\n",
        "y_pred_knn = knn_classifier.predict(X_val_features)\n",
        "knn_accuracy = accuracy_score(y_val, y_pred_knn)\n",
        "\n",
        "print(\"k-NN Training Complete.\")\n",
        "print(f\"k-NN (on CNN Features) Accuracy: {knn_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "B68ITV6qtF_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"\\n--- Starting SVM Comparison ---\")\n",
        "print(\"NOTE: SVM training is computationally intensive and may take a significant amount of time.\")\n",
        "\n",
        "\n",
        "svm_classifier = SVC(kernel='rbf', C=10, gamma='auto', random_state=42)\n",
        "\n",
        "svm_classifier.fit(X_train_features, y_train)\n",
        "\n",
        "print(\"SVM Training Complete.\")\n",
        "\n",
        "\n",
        "y_pred_svm = svm_classifier.predict(X_val_features)\n",
        "svm_accuracy = accuracy_score(y_val, y_pred_svm)\n",
        "\n",
        "print(f\"SVM (on CNN Features) Accuracy: {svm_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "pJwnBqyyt_jn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}